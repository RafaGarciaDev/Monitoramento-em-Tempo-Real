# ğŸš€ Guia de InÃ­cio RÃ¡pido

## Requisitos MÃ­nimos

- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM
- 20GB disco livre

## InstalaÃ§Ã£o em 3 Passos

### 1ï¸âƒ£ Clone e Configure

```bash
git clone https://github.com/seu-usuario/data-pipeline-monitoring.git
cd data-pipeline-monitoring
```

### 2ï¸âƒ£ Inicialize o Projeto

```bash
make init
```

Este comando irÃ¡:
- Criar estrutura de diretÃ³rios
- Configurar variÃ¡veis de ambiente
- Inicializar banco de dados do Airflow
- Iniciar todos os serviÃ§os

### 3ï¸âƒ£ Aguarde e Acesse

Aguarde 2-3 minutos para todos os serviÃ§os ficarem prontos.

## ğŸŒ Acessando os ServiÃ§os

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| **Airflow** | http://localhost:8080 | airflow / airflow |
| **Grafana** | http://localhost:3000 | admin / admin |
| **Prometheus** | http://localhost:9090 | - |
| **AlertManager** | http://localhost:9093 | - |

## ğŸ¯ Primeiros Passos no Airflow

1. Acesse http://localhost:8080
2. Login: `airflow` / `airflow`
3. VÃ¡ para **DAGs**
4. Ative os DAGs:
   - `monitored_etl_pipeline`
   - `data_quality_monitoring`
   - `sla_monitoring`
5. Clique em â–¶ï¸ para executar manualmente

## ğŸ“Š Visualizando MÃ©tricas no Grafana

1. Acesse http://localhost:3000
2. Login: `admin` / `admin`
3. VÃ¡ para **Dashboards**
4. Explore os dashboards prÃ©-configurados:
   - Pipeline Overview
   - Data Quality
   - SLA Tracking
   - Performance Analysis

## ğŸ”” Configurando Alertas

### Slack

Edite `monitoring/alertmanager/alertmanager.yml`:

```yaml
slack_configs:
  - api_url: 'SEU_WEBHOOK_URL'
    channel: '#data-alerts'
```

### Email

Edite `.env`:

```bash
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=seu-email@gmail.com
SMTP_PASSWORD=sua-senha-de-app
```

## ğŸ› ï¸ Comandos Ãšteis

```bash
# Ver logs
make logs-airflow

# Ver status
make ps

# Verificar saÃºde
make check-health

# Listar DAGs
make list-dags

# Executar DAG manualmente
make trigger-dag DAG=monitored_etl_pipeline

# Backup do banco
make db-backup

# Parar tudo
make down

# Limpar e recomeÃ§ar
make clean
make init
```

## ğŸ› Troubleshooting

### ServiÃ§os nÃ£o iniciam

```bash
# Ver logs
docker-compose logs

# Recriar containers
make clean
make init
```

### Porta em uso

Edite `docker-compose.yml` e altere as portas:

```yaml
ports:
  - "8081:8080"  # Airflow
  - "3001:3000"  # Grafana
```

### Sem espaÃ§o em disco

```bash
# Limpar logs antigos
make clean-logs

# Limpar volumes nÃ£o utilizados
docker volume prune
```

## ğŸ“š PrÃ³ximos Passos

1. âœ… Explore os DAGs de exemplo
2. âœ… Configure alertas para seu time
3. âœ… Customize os dashboards no Grafana
4. âœ… Crie seus prÃ³prios DAGs
5. âœ… Configure integraÃ§Ã£o com suas fontes de dados

## ğŸ†˜ Precisa de Ajuda?

- ğŸ“– Leia o [README.md](README.md) completo
- ğŸ› Abra uma [issue](https://github.com/seu-usuario/data-pipeline-monitoring/issues)
- ğŸ’¬ Entre em contato

## ğŸ‰ Tudo Pronto!

Seu ambiente de monitoramento de pipelines estÃ¡ configurado!

PrÃ³ximo passo: Explore os dashboards no Grafana e acompanhe a execuÃ§Ã£o dos DAGs no Airflow.

Happy Data Engineering! ğŸš€
