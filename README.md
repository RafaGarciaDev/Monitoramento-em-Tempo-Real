# ğŸ“Š Monitoramento de Data Pipelines

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=Prometheus&logoColor=white)
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

Sistema completo de monitoramento e observabilidade para data pipelines com Apache Airflow, incluindo alertas em tempo real, dashboards interativos, rastreamento de SLA e anÃ¡lise de performance.

## ğŸ¯ Sobre o Projeto

Este projeto demonstra a implementaÃ§Ã£o de um sistema robusto de monitoramento para data pipelines, essencial para garantir a confiabilidade e performance de processos de ETL/ELT em produÃ§Ã£o.

### Recursos Principais

- **ğŸ“ˆ Monitoramento em Tempo Real**: MÃ©tricas ao vivo de execuÃ§Ã£o de pipelines
- **ğŸš¨ Sistema de Alertas**: NotificaÃ§Ãµes via Slack/Email para falhas e SLA
- **ğŸ“Š Dashboards Interativos**: VisualizaÃ§Ãµes customizadas no Grafana
- **ğŸ” Rastreamento de Qualidade**: ValidaÃ§Ã£o de dados e qualidade
- **â±ï¸ AnÃ¡lise de Performance**: IdentificaÃ§Ã£o de gargalos e otimizaÃ§Ãµes
- **ğŸ“ Logs Centralizados**: AgregaÃ§Ã£o e busca eficiente de logs
- **ğŸ¯ SLA Tracking**: Monitoramento de acordos de nÃ­vel de serviÃ§o
- **ğŸ”„ Pipeline Lineage**: Rastreamento de dependÃªncias entre pipelines

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Sources                             â”‚
â”‚         (PostgreSQL, APIs, CSV, S3, BigQuery)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Apache Airflow                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Pipeline 1â”‚  â”‚Pipeline 2â”‚  â”‚Pipeline 3â”‚  â”‚Pipeline Nâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                      â”‚             â”‚                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚              â”‚   Metrics Exporter          â”‚               â”‚
â”‚              â”‚   - StatsD                  â”‚               â”‚
â”‚              â”‚   - Prometheus              â”‚               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Prometheuâ”‚   â”‚ Loki   â”‚   â”‚ElasticSâ”‚
    â”‚   s     â”‚   â”‚(Logs)  â”‚   â”‚  earch â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
              â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
              â”‚ Grafana â”‚
              â”‚Dashboardâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         â”‚         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”
    â”‚ Slack  â”‚ â”‚Email â”‚ â”‚PagerDâ”‚
    â”‚        â”‚ â”‚      â”‚ â”‚ uty  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Tecnologias Utilizadas

### Core
- **Apache Airflow 2.8**: OrquestraÃ§Ã£o de pipelines
- **PostgreSQL 15**: Backend do Airflow e data warehouse
- **Redis 7**: Celery broker para execuÃ§Ã£o distribuÃ­da

### Monitoramento
- **Prometheus**: Coleta e armazenamento de mÃ©tricas
- **Grafana**: VisualizaÃ§Ã£o e dashboards
- **Loki**: AgregaÃ§Ã£o de logs
- **AlertManager**: Gerenciamento de alertas

### Qualidade de Dados
- **Great Expectations**: ValidaÃ§Ã£o de qualidade de dados
- **dbt**: TransformaÃ§Ã£o e testes de dados

### Infraestrutura
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o
- **Nginx**: Reverse proxy
- **Python 3.11**: Scripts e operators customizados

## ğŸ“¦ Estrutura do Projeto

```
data-pipeline-monitoring/
â”‚
â”œâ”€â”€ airflow/                      # Apache Airflow
â”‚   â”œâ”€â”€ dags/                     # DAGs de exemplo
â”‚   â”‚   â”œâ”€â”€ example_etl.py       # Pipeline ETL simples
â”‚   â”‚   â”œâ”€â”€ data_quality.py      # Pipeline com validaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ ml_pipeline.py       # Pipeline de ML
â”‚   â”‚   â””â”€â”€ monitoring_dag.py    # Auto-monitoramento
â”‚   â”œâ”€â”€ plugins/                  # Plugins customizados
â”‚   â”‚   â”œâ”€â”€ operators/           # Operators personalizados
â”‚   â”‚   â”œâ”€â”€ sensors/             # Sensors customizados
â”‚   â”‚   â””â”€â”€ hooks/               # Hooks para integraÃ§Ãµes
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ airflow.cfg          # ConfiguraÃ§Ã£o do Airflow
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ monitoring/                   # Stack de monitoramento
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ prometheus.yml       # Config Prometheus
â”‚   â”‚   â”œâ”€â”€ alerts.yml          # Regras de alerta
â”‚   â”‚   â””â”€â”€ rules.yml           # Recording rules
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ dashboards/         # Dashboards JSON
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline-overview.json
â”‚   â”‚   â”‚   â”œâ”€â”€ data-quality.json
â”‚   â”‚   â”‚   â””â”€â”€ sla-tracking.json
â”‚   â”‚   â”œâ”€â”€ datasources/        # Data sources
â”‚   â”‚   â””â”€â”€ provisioning/       # Provisionamento
â”‚   â”œâ”€â”€ loki/
â”‚   â”‚   â””â”€â”€ loki-config.yml     # Config Loki
â”‚   â””â”€â”€ alertmanager/
â”‚       â””â”€â”€ alertmanager.yml    # Config alertas
â”‚
â”œâ”€â”€ data-quality/                 # ValidaÃ§Ã£o de qualidade
â”‚   â”œâ”€â”€ great_expectations/
â”‚   â”‚   â”œâ”€â”€ expectations/       # Expectativas de dados
â”‚   â”‚   â””â”€â”€ checkpoints/        # Checkpoints
â”‚   â””â”€â”€ dbt/
â”‚       â”œâ”€â”€ models/             # Modelos dbt
â”‚       â””â”€â”€ tests/              # Testes de dados
â”‚
â”œâ”€â”€ scripts/                      # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ metrics_exporter.py     # Exportador de mÃ©tricas
â”‚   â”œâ”€â”€ alert_handler.py        # Handler de alertas
â”‚   â”œâ”€â”€ sla_checker.py          # Verificador de SLA
â”‚   â””â”€â”€ data_profiler.py        # Profiler de dados
â”‚
â”œâ”€â”€ tests/                        # Testes
â”‚   â”œâ”€â”€ dags/                   # Testes de DAGs
â”‚   â”œâ”€â”€ integration/            # Testes de integraÃ§Ã£o
â”‚   â””â”€â”€ unit/                   # Testes unitÃ¡rios
â”‚
â”œâ”€â”€ docker-compose.yml           # OrquestraÃ§Ã£o
â”œâ”€â”€ .env.example                # VariÃ¡veis de ambiente
â”œâ”€â”€ Makefile                    # Comandos Ãºteis
â””â”€â”€ README.md
```

## ğŸ”§ PrÃ©-requisitos

- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM (mÃ­nimo)
- 20GB disco disponÃ­vel

## ğŸ“¥ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/data-pipeline-monitoring.git
cd data-pipeline-monitoring
```

### 2. Configure variÃ¡veis de ambiente

```bash
cp .env.example .env
# Edite o arquivo .env com suas credenciais
```

### 3. Inicie os serviÃ§os

```bash
# MÃ©todo 1: Usando Makefile
make init

# MÃ©todo 2: Docker Compose direto
docker-compose up -d

# Aguarde inicializaÃ§Ã£o (pode levar 2-3 minutos)
make wait-healthy
```

### 4. Acesse os serviÃ§os

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| **Airflow UI** | http://localhost:8080 | airflow/airflow |
| **Grafana** | http://localhost:3000 | admin/admin |
| **Prometheus** | http://localhost:9090 | - |
| **AlertManager** | http://localhost:9093 | - |

## ğŸ“Š Dashboards DisponÃ­veis

### 1. Pipeline Overview
- Total de pipelines ativos
- Taxa de sucesso/falha
- Tempo mÃ©dio de execuÃ§Ã£o
- Pipelines em execuÃ§Ã£o
- HistÃ³rico de execuÃ§Ãµes

### 2. Data Quality Dashboard
- Testes de qualidade executados
- Taxa de aprovaÃ§Ã£o
- Anomalias detectadas
- ValidaÃ§Ãµes por dataset
- TendÃªncias de qualidade

### 3. SLA Tracking
- Cumprimento de SLAs
- Pipelines em risco
- Tempo atÃ© deadline
- HistÃ³rico de violaÃ§Ãµes
- PrevisÃµes de atraso

### 4. Performance Analysis
- CPU e memÃ³ria por pipeline
- I/O de disco
- Tempo por task
- Gargalos identificados
- RecomendaÃ§Ãµes de otimizaÃ§Ã£o

## ğŸš¨ Sistema de Alertas

### Alertas Configurados

1. **Pipeline Failure**: Falha em qualquer pipeline
2. **SLA Violation**: ViolaÃ§Ã£o de SLA
3. **Data Quality Issues**: Problemas de qualidade
4. **Performance Degradation**: DegradaÃ§Ã£o de performance
5. **Resource Exhaustion**: Recursos esgotando
6. **Long Running Tasks**: Tasks demorando muito

### ConfiguraÃ§Ã£o de NotificaÃ§Ãµes

#### Slack

```yaml
# monitoring/alertmanager/alertmanager.yml
receivers:
  - name: 'slack'
    slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'
        channel: '#data-alerts'
        title: 'Pipeline Alert'
```

#### Email

```yaml
receivers:
  - name: 'email'
    email_configs:
      - to: 'team@example.com'
        from: 'airflow@example.com'
        smarthost: 'smtp.gmail.com:587'
```

## ğŸ“ˆ MÃ©tricas Coletadas

### MÃ©tricas de Pipeline
- `airflow_dag_run_total`: Total de execuÃ§Ãµes por DAG
- `airflow_dag_run_duration_seconds`: DuraÃ§Ã£o das execuÃ§Ãµes
- `airflow_task_duration_seconds`: DuraÃ§Ã£o por task
- `airflow_task_failures_total`: Total de falhas
- `airflow_scheduler_heartbeat`: Heartbeat do scheduler

### MÃ©tricas de Qualidade
- `data_quality_tests_total`: Total de testes
- `data_quality_failures_total`: Testes falhados
- `data_completeness_ratio`: Completude dos dados
- `data_freshness_seconds`: Frescor dos dados
- `schema_violations_total`: ViolaÃ§Ãµes de schema

### MÃ©tricas de Performance
- `pipeline_cpu_usage_percent`: Uso de CPU
- `pipeline_memory_usage_bytes`: Uso de memÃ³ria
- `pipeline_io_operations_total`: OperaÃ§Ãµes de I/O
- `pipeline_rows_processed_total`: Linhas processadas

## ğŸ” Exemplo de DAG com Monitoramento

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
from datetime import timedelta
import logging

# ConfiguraÃ§Ã£o de SLA
default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'email': ['alerts@example.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2),  # SLA de 2 horas
}

dag = DAG(
    'monitored_etl_pipeline',
    default_args=default_args,
    description='Pipeline ETL com monitoramento completo',
    schedule_interval='0 */6 * * *',  # A cada 6 horas
    start_date=days_ago(1),
    catchup=False,
    tags=['etl', 'production', 'monitored'],
)

def extract_data(**context):
    """Extrai dados com mÃ©tricas"""
    from prometheus_client import Counter, Histogram
    import time
    
    # MÃ©tricas
    rows_extracted = Counter('rows_extracted_total', 'Total rows extracted')
    extraction_duration = Histogram('extraction_duration_seconds', 'Extraction time')
    
    start_time = time.time()
    
    # LÃ³gica de extraÃ§Ã£o
    rows = 10000
    rows_extracted.inc(rows)
    
    duration = time.time() - start_time
    extraction_duration.observe(duration)
    
    logging.info(f"Extracted {rows} rows in {duration:.2f}s")
    return rows

def validate_quality(**context):
    """Valida qualidade dos dados"""
    # IntegraÃ§Ã£o com Great Expectations
    pass

extract = PythonOperator(
    task_id='extract_data',
    python_callable=extract_data,
    dag=dag,
)

validate = PythonOperator(
    task_id='validate_quality',
    python_callable=validate_quality,
    dag=dag,
)

extract >> validate
```

## ğŸ§ª Testes

```bash
# Testar DAGs
make test-dags

# Testes unitÃ¡rios
make test-unit

# Testes de integraÃ§Ã£o
make test-integration

# Validar configuraÃ§Ã£o do Airflow
make validate-airflow
```

## ğŸ› ï¸ Comandos Ãšteis

```bash
# Visualizar logs
make logs                    # Todos os serviÃ§os
make logs-airflow           # Apenas Airflow
make logs-prometheus        # Apenas Prometheus

# Gerenciar serviÃ§os
make start                  # Iniciar
make stop                   # Parar
make restart                # Reiniciar
make clean                  # Limpar tudo

# Monitoramento
make check-health          # Verificar saÃºde
make stats                 # EstatÃ­sticas de recursos
make export-metrics        # Exportar mÃ©tricas

# Desenvolvimento
make shell-airflow         # Shell do Airflow
make airflow-db-upgrade    # Upgrade do DB
make create-user           # Criar usuÃ¡rio
```

## ğŸ“Š AnÃ¡lise de Performance

### Identificar Gargalos

1. Acesse Grafana â†’ Performance Analysis Dashboard
2. Filtre por pipeline especÃ­fico
3. Analise:
   - Tempo por task
   - Uso de recursos
   - I/O operations
   - Network latency

### OtimizaÃ§Ãµes Comuns

- **ParalelizaÃ§Ã£o**: Aumentar `max_active_tasks_per_dag`
- **Pool Management**: Criar pools dedicados
- **Recursos**: Ajustar CPU/memÃ³ria por task
- **Retry Logic**: Otimizar estratÃ©gia de retry
- **Caching**: Implementar cache de resultados

## ğŸ” SeguranÃ§a e Boas PrÃ¡ticas

- âœ… Secrets gerenciados via variÃ¡veis de ambiente
- âœ… RBAC habilitado no Airflow
- âœ… SSL/TLS em produÃ§Ã£o
- âœ… Backup automÃ¡tico de metadados
- âœ… Auditoria de acessos
- âœ… RotaÃ§Ã£o de credenciais

## ğŸš€ Deploy em ProduÃ§Ã£o

### Kubernetes (Recomendado)

```bash
# Usar Helm Chart oficial do Airflow
helm repo add apache-airflow https://airflow.apache.org
helm install airflow apache-airflow/airflow \
  --namespace airflow \
  --values production-values.yaml
```

### Cloud Providers

- **AWS**: Amazon MWAA (Managed Workflows for Apache Airflow)
- **GCP**: Cloud Composer
- **Azure**: Data Factory + Airflow

## ğŸ“ˆ Roadmap

- [ ] IntegraÃ§Ã£o com dbt Cloud
- [ ] ML Pipeline monitoring
- [ ] Cost tracking e otimizaÃ§Ã£o
- [ ] Data lineage visualization
- [ ] Auto-scaling baseado em carga
- [ ] Disaster recovery automation

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Veja [CONTRIBUTING.md](CONTRIBUTING.md) para detalhes.

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja [LICENSE](LICENSE) para mais detalhes.

## ğŸ‘¤ Autor

**Seu Nome**

- GitHub: [@seu-usuario](https://github.com/seu-usuario)
- LinkedIn: [seu-perfil](https://linkedin.com/in/seu-perfil)
- Email: seu-email@example.com

## ğŸ™ Agradecimentos

- Apache Airflow Community
- Prometheus & Grafana Teams
- Great Expectations Team

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Airflow](https://airflow.apache.org/docs/)
- [Guia Prometheus](https://prometheus.io/docs/)
- [Grafana Tutorials](https://grafana.com/tutorials/)
- [Great Expectations](https://docs.greatexpectations.io/)

---

â­ Se este projeto foi Ãºtil, considere dar uma estrela!

**Nota**: Este projeto Ã© uma demonstraÃ§Ã£o para portfÃ³lio. Para uso em produÃ§Ã£o, considere aspectos adicionais de seguranÃ§a, escalabilidade e conformidade.
